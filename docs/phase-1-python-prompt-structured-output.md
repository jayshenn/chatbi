# é˜¶æ®µ 1ï¼šPython å®æˆ˜ + Prompt å·¥ç¨‹ + ç»“æ„åŒ–è¾“å‡º

> é¢„è®¡æ—¶é—´ï¼š2-3 å‘¨

## å­¦ä¹ ç›®æ ‡

- å¼ºåŒ– Python æ•°æ®å¤„ç†èƒ½åŠ›ï¼ˆæ–‡ä»¶è¯»å†™ã€pandasã€å¼‚æ­¥ï¼‰
- æŒæ¡ Prompt å·¥ç¨‹åŸºç¡€æŠ€å·§
- ä½¿ç”¨ Pydantic v2 å®ç° LLM ç»“æ„åŒ–è¾“å‡º
- å®Œæˆå°é¡¹ç›®ï¼šSQL è§£é‡ŠåŠ©æ‰‹

## å‰ç½®æ¡ä»¶

- å®Œæˆ [é˜¶æ®µ 0](phase-0-python-engineering-llm-infra.md)
- é¡¹ç›®åŸºç¡€æ¡†æ¶å·²æ­å»ºå®Œæˆ

---

## Step 1: Python æ•°æ®å¤„ç†å¼ºåŒ–

### 1.1 æ·»åŠ ä¾èµ–

æ›´æ–° `pyproject.toml`ï¼š

```toml
dependencies = [
    # ... å·²æœ‰ä¾èµ–
    "pandas>=2.2.0",
    "aiofiles>=24.1.0",
]
```

å®‰è£…ï¼š

```bash
uv pip install -e ".[dev]"
```

### 1.2 åˆ›å»ºæ•°æ®å¤„ç†å·¥å…·æ¨¡å—

åˆ›å»º `src/chatbi/utils/data.py`ï¼š

```python
"""æ•°æ®å¤„ç†å·¥å…·"""

import csv
import json
from pathlib import Path
from typing import Any

import pandas as pd


def read_csv(file_path: str | Path) -> pd.DataFrame:
    """è¯»å– CSV æ–‡ä»¶"""
    return pd.read_csv(file_path)


def read_json(file_path: str | Path) -> dict | list:
    """è¯»å– JSON æ–‡ä»¶"""
    with open(file_path, "r", encoding="utf-8") as f:
        return json.load(f)


def write_json(data: Any, file_path: str | Path, indent: int = 2) -> None:
    """å†™å…¥ JSON æ–‡ä»¶"""
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=indent)


def read_markdown(file_path: str | Path) -> str:
    """è¯»å– Markdown æ–‡ä»¶"""
    with open(file_path, "r", encoding="utf-8") as f:
        return f.read()


def dataframe_to_markdown(df: pd.DataFrame, max_rows: int = 10) -> str:
    """DataFrame è½¬ Markdown è¡¨æ ¼"""
    if len(df) > max_rows:
        df = df.head(max_rows)
    return df.to_markdown(index=False)


def dataframe_summary(df: pd.DataFrame) -> dict:
    """ç”Ÿæˆ DataFrame æ‘˜è¦ä¿¡æ¯"""
    return {
        "shape": df.shape,
        "columns": list(df.columns),
        "dtypes": df.dtypes.astype(str).to_dict(),
        "null_counts": df.isnull().sum().to_dict(),
        "sample": df.head(3).to_dict(orient="records"),
    }
```

### 1.3 Pandas å¸¸ç”¨æ“ä½œç¤ºä¾‹

åˆ›å»º `src/chatbi/utils/pandas_examples.py`ï¼ˆä»…ä½œå­¦ä¹ å‚è€ƒï¼‰ï¼š

```python
"""Pandas å¸¸ç”¨æ“ä½œç¤ºä¾‹"""

import pandas as pd


def demo_pandas_operations():
    """æ¼”ç¤ºå¸¸ç”¨ Pandas æ“ä½œ"""

    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    df = pd.DataFrame(
        {
            "date": pd.date_range("2024-01-01", periods=10),
            "user_id": [1, 2, 1, 3, 2, 1, 4, 3, 2, 1],
            "amount": [100, 200, 150, 300, 250, 120, 180, 220, 190, 160],
            "category": ["A", "B", "A", "C", "B", "A", "C", "C", "B", "A"],
        }
    )

    # 1. è¿‡æ»¤
    filtered = df[df["amount"] > 150]

    # 2. åˆ†ç»„èšåˆ
    grouped = df.groupby("category").agg(
        total_amount=("amount", "sum"),
        avg_amount=("amount", "mean"),
        count=("amount", "count"),
    )

    # 3. æ’åº
    sorted_df = df.sort_values("amount", ascending=False)

    # 4. å¤šæ¡ä»¶è¿‡æ»¤
    complex_filter = df[(df["amount"] > 100) & (df["category"].isin(["A", "B"]))]

    # 5. é€è§†è¡¨
    pivot = df.pivot_table(
        values="amount", index="category", columns="user_id", aggfunc="sum", fill_value=0
    )

    return {
        "original": df,
        "filtered": filtered,
        "grouped": grouped,
        "sorted": sorted_df,
        "complex_filter": complex_filter,
        "pivot": pivot,
    }
```

### 1.4 å¼‚æ­¥ç¼–ç¨‹åŸºç¡€

åˆ›å»º `src/chatbi/utils/async_utils.py`ï¼š

```python
"""å¼‚æ­¥å·¥å…·"""

import asyncio
from typing import Any, Callable, Coroutine

import aiofiles


async def read_file_async(file_path: str) -> str:
    """å¼‚æ­¥è¯»å–æ–‡ä»¶"""
    async with aiofiles.open(file_path, "r", encoding="utf-8") as f:
        return await f.read()


async def write_file_async(file_path: str, content: str) -> None:
    """å¼‚æ­¥å†™å…¥æ–‡ä»¶"""
    async with aiofiles.open(file_path, "w", encoding="utf-8") as f:
        await f.write(content)


async def gather_with_concurrency(
    n: int, *coros: Coroutine[Any, Any, Any]
) -> list[Any]:
    """
    é™åˆ¶å¹¶å‘æ•°é‡çš„ gather

    Args:
        n: æœ€å¤§å¹¶å‘æ•°
        *coros: åç¨‹åˆ—è¡¨
    """
    semaphore = asyncio.Semaphore(n)

    async def sem_coro(coro: Coroutine[Any, Any, Any]) -> Any:
        async with semaphore:
            return await coro

    return await asyncio.gather(*(sem_coro(c) for c in coros))
```

---

## Step 2: Prompt å·¥ç¨‹åŸºç¡€

### 2.1 åˆ›å»º Prompt æ¨¡æ¿æ¨¡å—

åˆ›å»º `src/chatbi/prompts/__init__.py`ï¼š

```python
"""Prompt æ¨¡æ¿æ¨¡å—"""

from chatbi.prompts.templates import PromptTemplate

__all__ = ["PromptTemplate"]
```

åˆ›å»º `src/chatbi/prompts/templates.py`ï¼š

```python
"""Prompt æ¨¡æ¿å®šä¹‰"""

from string import Template
from typing import Any


class PromptTemplate:
    """
    Prompt æ¨¡æ¿ç±»

    æ”¯æŒä½¿ç”¨ $variable æˆ– ${variable} è¯­æ³•è¿›è¡Œå˜é‡æ›¿æ¢
    """

    def __init__(self, template: str):
        self.template = Template(template)
        self._raw = template

    def format(self, **kwargs: Any) -> str:
        """æ ¼å¼åŒ–æ¨¡æ¿"""
        return self.template.safe_substitute(**kwargs)

    def __str__(self) -> str:
        return self._raw


# ========== é€šç”¨ Prompt æ¨¡æ¿ ==========

SYSTEM_ROLE_TEMPLATE = PromptTemplate(
    """ä½ æ˜¯ä¸€ä¸ª${role}ã€‚

## ä½ çš„èŒè´£
${responsibilities}

## çº¦æŸæ¡ä»¶
${constraints}
"""
)

JSON_OUTPUT_TEMPLATE = PromptTemplate(
    """è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚ç”Ÿæˆ JSON æ ¼å¼çš„è¾“å‡ºã€‚

## ä»»åŠ¡æè¿°
${task}

## è¾“å…¥å†…å®¹
${input}

## è¾“å‡ºæ ¼å¼è¦æ±‚
è¾“å‡ºå¿…é¡»æ˜¯æœ‰æ•ˆçš„ JSONï¼Œç»“æ„å¦‚ä¸‹ï¼š
```json
${schema}
```

## æ³¨æ„äº‹é¡¹
- åªè¾“å‡º JSONï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹
- ç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½æœ‰å€¼
- å­—ç¬¦ä¸²å€¼ä½¿ç”¨åŒå¼•å·
"""
)

FEW_SHOT_TEMPLATE = PromptTemplate(
    """${task_description}

## ç¤ºä¾‹

${examples}

## ç°åœ¨è¯·å¤„ç†ä»¥ä¸‹è¾“å…¥

è¾“å…¥ï¼š${input}
è¾“å‡ºï¼š"""
)
```

### 2.2 SQL è§£é‡ŠåŠ©æ‰‹ Prompt

åˆ›å»º `src/chatbi/prompts/sql_explainer.py`ï¼š

```python
"""SQL è§£é‡ŠåŠ©æ‰‹ Prompt"""

from chatbi.prompts.templates import PromptTemplate

SQL_EXPLAINER_SYSTEM = """ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„æ•°æ®åˆ†æä¸“å®¶ï¼Œæ“…é•¿è§£è¯»å¤æ‚çš„ SQL æŸ¥è¯¢ã€‚

## ä½ çš„èŒè´£
- åˆ†æ SQL æŸ¥è¯¢çš„ç»“æ„å’Œé€»è¾‘
- æå–æŸ¥è¯¢çš„å…³é”®ä¿¡æ¯ï¼ˆæŒ‡æ ‡ã€è¿‡æ»¤æ¡ä»¶ã€åˆ†ç»„ã€å…³è”ç­‰ï¼‰
- ç”¨ä¸šåŠ¡è¯­è¨€è§£é‡Š SQL çš„å«ä¹‰

## è¾“å‡ºè¦æ±‚
- è¾“å‡ºå¿…é¡»æ˜¯ä¸¥æ ¼çš„ JSON æ ¼å¼
- æ‰€æœ‰å­—æ®µå¿…é¡»å¡«å†™ï¼Œå¦‚æœæ²¡æœ‰ç›¸å…³å†…å®¹åˆ™ä½¿ç”¨ç©ºæ•°ç»„ []
- business_explanation å¿…é¡»ç”¨ä¸­æ–‡ï¼Œç®€æ´æ˜äº†
"""

SQL_EXPLAINER_USER = PromptTemplate(
    """è¯·åˆ†æä»¥ä¸‹ SQL æŸ¥è¯¢ï¼Œå¹¶ä»¥ JSON æ ¼å¼è¾“å‡ºåˆ†æç»“æœã€‚

## SQL æŸ¥è¯¢
```sql
${sql}
```

${sample_data_section}

## è¾“å‡º JSON ç»“æ„
```json
{
    "target_metrics": ["æŸ¥è¯¢è¦è·å–çš„æŒ‡æ ‡æˆ–å­—æ®µï¼Œå¦‚ SUM(amount), COUNT(*)"],
    "filters": ["WHERE æ¡ä»¶ä¸­çš„è¿‡æ»¤é€»è¾‘"],
    "group_by": ["GROUP BY çš„å­—æ®µ"],
    "joins": ["è¡¨å…³è”ä¿¡æ¯ï¼Œæ ¼å¼ï¼šè¡¨A JOIN è¡¨B ON æ¡ä»¶"],
    "order_by": ["æ’åºä¿¡æ¯"],
    "business_explanation": "ç”¨ä¸šåŠ¡è¯­è¨€è§£é‡Šè¿™ä¸ªæŸ¥è¯¢åœ¨åšä»€ä¹ˆ"
}
```

è¯·ç›´æ¥è¾“å‡º JSONï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ã€‚
"""
)


def build_sql_explainer_prompt(sql: str, sample_data: str | None = None) -> str:
    """
    æ„å»º SQL è§£é‡Š Prompt

    Args:
        sql: SQL æŸ¥è¯¢è¯­å¥
        sample_data: å¯é€‰çš„ç¤ºä¾‹æ•°æ®ï¼ˆCSV æ ¼å¼ï¼‰
    """
    sample_section = ""
    if sample_data:
        sample_section = f"""
## å‚è€ƒæ•°æ®æ ·ä¾‹
```csv
{sample_data}
```
"""

    return SQL_EXPLAINER_USER.format(sql=sql, sample_data_section=sample_section)
```

---

## Step 3: Pydantic v2 ç»“æ„åŒ–è¾“å‡º

### 3.1 åˆ›å»º SQL è§£é‡Šæ¨¡å‹

åˆ›å»º `src/chatbi/models/__init__.py`ï¼š

```python
"""æ•°æ®æ¨¡å‹"""

from chatbi.models.sql import SqlExplanation

__all__ = ["SqlExplanation"]
```

åˆ›å»º `src/chatbi/models/sql.py`ï¼š

```python
"""SQL ç›¸å…³æ•°æ®æ¨¡å‹"""

from pydantic import BaseModel, Field


class SqlExplanation(BaseModel):
    """SQL è§£é‡Šç»“æœ"""

    target_metrics: list[str] = Field(
        default_factory=list,
        description="æŸ¥è¯¢è¦è·å–çš„æŒ‡æ ‡æˆ–å­—æ®µ",
    )
    filters: list[str] = Field(
        default_factory=list,
        description="WHERE æ¡ä»¶ä¸­çš„è¿‡æ»¤é€»è¾‘",
    )
    group_by: list[str] = Field(
        default_factory=list,
        description="GROUP BY çš„å­—æ®µ",
    )
    joins: list[str] = Field(
        default_factory=list,
        description="è¡¨å…³è”ä¿¡æ¯",
    )
    order_by: list[str] = Field(
        default_factory=list,
        description="æ’åºä¿¡æ¯",
    )
    business_explanation: str = Field(
        default="",
        description="ä¸šåŠ¡è¯­è¨€è§£é‡Š",
    )

    model_config = {
        "json_schema_extra": {
            "example": {
                "target_metrics": ["SUM(order_amount) as total_gmv", "COUNT(DISTINCT user_id) as user_count"],
                "filters": ["order_date >= '2024-01-01'", "status = 'completed'"],
                "group_by": ["DATE(order_date)", "category"],
                "joins": ["orders JOIN users ON orders.user_id = users.id"],
                "order_by": ["total_gmv DESC"],
                "business_explanation": "ç»Ÿè®¡2024å¹´ä»¥æ¥å„å“ç±»æ¯å¤©çš„GMVå’Œä¸‹å•ç”¨æˆ·æ•°ï¼ŒæŒ‰GMVé™åºæ’åˆ—",
            }
        }
    }
```

### 3.2 åˆ›å»º JSON è§£æå·¥å…·

åˆ›å»º `src/chatbi/utils/json_parser.py`ï¼š

```python
"""JSON è§£æå·¥å…·"""

import json
import re
from typing import Type, TypeVar

from pydantic import BaseModel, ValidationError

T = TypeVar("T", bound=BaseModel)


class JsonParseError(Exception):
    """JSON è§£æé”™è¯¯"""

    def __init__(self, message: str, raw_content: str):
        super().__init__(message)
        self.raw_content = raw_content


def extract_json_from_text(text: str) -> str:
    """
    ä»æ–‡æœ¬ä¸­æå– JSON å†…å®¹

    å¤„ç†ä»¥ä¸‹æƒ…å†µï¼š
    1. çº¯ JSON æ–‡æœ¬
    2. Markdown ä»£ç å—ä¸­çš„ JSON
    3. å¸¦æœ‰å‰åè¯´æ˜æ–‡å­—çš„ JSON
    """
    # å°è¯•åŒ¹é… ```json ... ``` ä»£ç å—
    json_block_pattern = r"```(?:json)?\s*([\s\S]*?)```"
    matches = re.findall(json_block_pattern, text)
    if matches:
        return matches[0].strip()

    # å°è¯•åŒ¹é… { ... } æˆ– [ ... ]
    # æ‰¾åˆ°ç¬¬ä¸€ä¸ª { æˆ– [ å’Œæœ€åä¸€ä¸ª } æˆ– ]
    text = text.strip()

    # æŸ¥æ‰¾ JSON å¯¹è±¡
    obj_start = text.find("{")
    obj_end = text.rfind("}")

    # æŸ¥æ‰¾ JSON æ•°ç»„
    arr_start = text.find("[")
    arr_end = text.rfind("]")

    # é€‰æ‹©æ›´æ—©å‡ºç°çš„èµ·å§‹ç¬¦å·
    if obj_start >= 0 and (arr_start < 0 or obj_start < arr_start):
        if obj_end > obj_start:
            return text[obj_start : obj_end + 1]
    elif arr_start >= 0:
        if arr_end > arr_start:
            return text[arr_start : arr_end + 1]

    return text


def parse_json_response(text: str, model: Type[T]) -> T:
    """
    è§£æ LLM è¿”å›çš„ JSON å¹¶æ ¡éªŒ

    Args:
        text: LLM è¿”å›çš„åŸå§‹æ–‡æœ¬
        model: Pydantic æ¨¡å‹ç±»

    Returns:
        è§£æå¹¶æ ¡éªŒåçš„æ¨¡å‹å®ä¾‹

    Raises:
        JsonParseError: JSON è§£ææˆ–æ ¡éªŒå¤±è´¥
    """
    try:
        # æå– JSON
        json_str = extract_json_from_text(text)

        # è§£æ JSON
        data = json.loads(json_str)

        # Pydantic æ ¡éªŒ
        return model.model_validate(data)

    except json.JSONDecodeError as e:
        raise JsonParseError(f"JSON è§£æå¤±è´¥: {e}", text)
    except ValidationError as e:
        raise JsonParseError(f"æ•°æ®æ ¡éªŒå¤±è´¥: {e}", text)
```

---

## Step 4: å®ç° SQL è§£é‡ŠåŠ©æ‰‹

### 4.1 åˆ›å»ºæ ¸å¿ƒæœåŠ¡

åˆ›å»º `src/chatbi/services/__init__.py`ï¼š

```python
"""ä¸šåŠ¡æœåŠ¡æ¨¡å—"""
```

åˆ›å»º `src/chatbi/services/sql_explainer.py`ï¼š

```python
"""SQL è§£é‡ŠæœåŠ¡"""

from chatbi.llm import chat_completion
from chatbi.models.sql import SqlExplanation
from chatbi.prompts.sql_explainer import SQL_EXPLAINER_SYSTEM, build_sql_explainer_prompt
from chatbi.utils.json_parser import JsonParseError, parse_json_response


class SqlExplainerService:
    """SQL è§£é‡ŠæœåŠ¡"""

    def __init__(self, max_retries: int = 2):
        self.max_retries = max_retries

    def explain(self, sql: str, sample_data: str | None = None) -> SqlExplanation:
        """
        è§£é‡Š SQL æŸ¥è¯¢

        Args:
            sql: SQL æŸ¥è¯¢è¯­å¥
            sample_data: å¯é€‰çš„ç¤ºä¾‹æ•°æ®ï¼ˆCSV æ ¼å¼ï¼‰

        Returns:
            SQL è§£é‡Šç»“æœ
        """
        user_prompt = build_sql_explainer_prompt(sql, sample_data)

        messages = [
            {"role": "system", "content": SQL_EXPLAINER_SYSTEM},
            {"role": "user", "content": user_prompt},
        ]

        last_error = None

        for attempt in range(self.max_retries + 1):
            try:
                response = chat_completion(messages, temperature=0.3)
                return parse_json_response(response, SqlExplanation)

            except JsonParseError as e:
                last_error = e
                if attempt < self.max_retries:
                    # æ·»åŠ é”™è¯¯åé¦ˆï¼Œè¦æ±‚é‡æ–°ç”Ÿæˆ
                    messages.append({"role": "assistant", "content": e.raw_content})
                    messages.append(
                        {
                            "role": "user",
                            "content": f"ä¸Šé¢çš„è¾“å‡ºä¸æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼ï¼Œé”™è¯¯ï¼š{str(e)}ã€‚è¯·é‡æ–°è¾“å‡ºï¼Œç¡®ä¿æ˜¯ä¸¥æ ¼çš„ JSON æ ¼å¼ã€‚",
                        }
                    )

        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        raise last_error


# åˆ›å»ºé»˜è®¤å®ä¾‹
sql_explainer = SqlExplainerService()
```

### 4.2 æ·»åŠ  API æ¥å£

æ›´æ–° `src/chatbi/main.py`ï¼Œæ·»åŠ  SQL è§£é‡Šæ¥å£ï¼š

```python
from chatbi.models.sql import SqlExplanation
from chatbi.services.sql_explainer import sql_explainer
from chatbi.utils.json_parser import JsonParseError


class ExplainSqlRequest(BaseModel):
    """SQL è§£é‡Šè¯·æ±‚"""

    sql: str
    sample_data: str | None = None


class ExplainSqlResponse(BaseModel):
    """SQL è§£é‡Šå“åº”"""

    success: bool
    data: SqlExplanation | None = None
    error: str | None = None


@app.post("/explain_sql", response_model=ExplainSqlResponse)
async def explain_sql(request: ExplainSqlRequest):
    """è§£é‡Š SQL æŸ¥è¯¢"""
    try:
        result = sql_explainer.explain(request.sql, request.sample_data)
        return ExplainSqlResponse(success=True, data=result)
    except JsonParseError as e:
        return ExplainSqlResponse(success=False, error=str(e))
    except Exception as e:
        return ExplainSqlResponse(success=False, error=f"æœåŠ¡é”™è¯¯: {str(e)}")
```

### 4.3 åˆ›å»º CLI å·¥å…·

åˆ›å»º `src/chatbi/cli/__init__.py`ï¼š

```python
"""CLI å·¥å…·"""
```

åˆ›å»º `src/chatbi/cli/sql_explainer.py`ï¼š

```python
"""SQL è§£é‡Šå™¨ CLI"""

import argparse
import json
import sys

from chatbi.services.sql_explainer import sql_explainer
from chatbi.utils.json_parser import JsonParseError


def main():
    parser = argparse.ArgumentParser(description="SQL è§£é‡ŠåŠ©æ‰‹")
    parser.add_argument("--sql", type=str, help="SQL æŸ¥è¯¢è¯­å¥")
    parser.add_argument("--file", type=str, help="åŒ…å« SQL çš„æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--sample", type=str, help="ç¤ºä¾‹æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆCSVï¼‰")
    parser.add_argument("--output", type=str, choices=["json", "text"], default="text", help="è¾“å‡ºæ ¼å¼")

    args = parser.parse_args()

    # è·å– SQL
    sql = None
    if args.sql:
        sql = args.sql
    elif args.file:
        with open(args.file, "r", encoding="utf-8") as f:
            sql = f.read()
    else:
        print("è¯·é€šè¿‡ --sql æˆ– --file æä¾› SQL æŸ¥è¯¢", file=sys.stderr)
        sys.exit(1)

    # è·å–ç¤ºä¾‹æ•°æ®
    sample_data = None
    if args.sample:
        with open(args.sample, "r", encoding="utf-8") as f:
            sample_data = f.read()

    # è°ƒç”¨æœåŠ¡
    try:
        result = sql_explainer.explain(sql, sample_data)

        if args.output == "json":
            print(result.model_dump_json(indent=2))
        else:
            print("\n=== SQL è§£é‡Šç»“æœ ===\n")
            print(f"ğŸ“Š ç›®æ ‡æŒ‡æ ‡: {', '.join(result.target_metrics) or 'æ— '}")
            print(f"ğŸ” è¿‡æ»¤æ¡ä»¶: {', '.join(result.filters) or 'æ— '}")
            print(f"ğŸ“ åˆ†ç»„å­—æ®µ: {', '.join(result.group_by) or 'æ— '}")
            print(f"ğŸ”— è¡¨å…³è”: {', '.join(result.joins) or 'æ— '}")
            print(f"ğŸ“ˆ æ’åº: {', '.join(result.order_by) or 'æ— '}")
            print(f"\nğŸ’¡ ä¸šåŠ¡è§£é‡Š:\n{result.business_explanation}")

    except JsonParseError as e:
        print(f"è§£æé”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
```

åœ¨ `pyproject.toml` ä¸­æ·»åŠ å…¥å£ç‚¹ï¼š

```toml
[project.scripts]
sql-explainer = "chatbi.cli.sql_explainer:main"
```

é‡æ–°å®‰è£…ï¼š

```bash
uv pip install -e ".[dev]"
```

---

## Step 5: æµ‹è¯• SQL è§£é‡ŠåŠ©æ‰‹

### 5.1 API æµ‹è¯•

```bash
# å¯åŠ¨æœåŠ¡
uvicorn chatbi.main:app --reload

# æµ‹è¯•ç®€å• SQL
curl -X POST http://localhost:8000/explain_sql \
  -H "Content-Type: application/json" \
  -d '{
    "sql": "SELECT category, SUM(amount) as total FROM orders WHERE status = '\''completed'\'' GROUP BY category ORDER BY total DESC LIMIT 10"
  }'

# æµ‹è¯•å¤æ‚ SQL
curl -X POST http://localhost:8000/explain_sql \
  -H "Content-Type: application/json" \
  -d '{
    "sql": "SELECT u.name, COUNT(o.id) as order_count, SUM(o.amount) as total_amount FROM users u LEFT JOIN orders o ON u.id = o.user_id WHERE o.created_at >= '\''2024-01-01'\'' AND o.status IN ('\''completed'\'', '\''shipped'\'') GROUP BY u.id, u.name HAVING COUNT(o.id) > 5 ORDER BY total_amount DESC"
  }'
```

### 5.2 CLI æµ‹è¯•

```bash
# ç›´æ¥ä¼ å…¥ SQL
sql-explainer --sql "SELECT * FROM users WHERE age > 18"

# JSON è¾“å‡º
sql-explainer --sql "SELECT category, COUNT(*) FROM products GROUP BY category" --output json

# ä»æ–‡ä»¶è¯»å–
echo "SELECT * FROM orders WHERE date > '2024-01-01'" > /tmp/test.sql
sql-explainer --file /tmp/test.sql
```

### 5.3 ç¼–å†™å•å…ƒæµ‹è¯•

åˆ›å»º `tests/test_sql_explainer.py`ï¼š

```python
"""SQL è§£é‡Šå™¨æµ‹è¯•"""

import pytest
from chatbi.models.sql import SqlExplanation
from chatbi.utils.json_parser import extract_json_from_text, parse_json_response


def test_extract_json_from_markdown():
    """æµ‹è¯•ä» Markdown æå– JSON"""
    text = """
è¿™æ˜¯ä¸€äº›è¯´æ˜æ–‡å­—ã€‚

```json
{"key": "value"}
```

ç»“æŸã€‚
"""
    result = extract_json_from_text(text)
    assert result == '{"key": "value"}'


def test_extract_json_direct():
    """æµ‹è¯•ç›´æ¥ JSON"""
    text = '{"target_metrics": ["COUNT(*)"], "filters": []}'
    result = extract_json_from_text(text)
    assert "target_metrics" in result


def test_parse_sql_explanation():
    """æµ‹è¯•è§£æ SQL è§£é‡Šç»“æœ"""
    json_text = """
{
    "target_metrics": ["SUM(amount)"],
    "filters": ["status = 'completed'"],
    "group_by": ["category"],
    "joins": [],
    "order_by": [],
    "business_explanation": "æŒ‰ç±»åˆ«ç»Ÿè®¡å·²å®Œæˆè®¢å•é‡‘é¢"
}
"""
    result = parse_json_response(json_text, SqlExplanation)
    assert result.target_metrics == ["SUM(amount)"]
    assert result.business_explanation == "æŒ‰ç±»åˆ«ç»Ÿè®¡å·²å®Œæˆè®¢å•é‡‘é¢"


def test_sql_explanation_model():
    """æµ‹è¯• SqlExplanation æ¨¡å‹"""
    data = {
        "target_metrics": ["COUNT(*)"],
        "filters": [],
        "group_by": [],
        "joins": [],
        "order_by": [],
        "business_explanation": "ç»Ÿè®¡æ€»æ•°",
    }
    model = SqlExplanation.model_validate(data)
    assert model.target_metrics == ["COUNT(*)"]
```

è¿è¡Œæµ‹è¯•ï¼š

```bash
pytest tests/test_sql_explainer.py -v
```

---

## é¡¹ç›®ç»“æ„æ£€æŸ¥

å®Œæˆæœ¬é˜¶æ®µåï¼Œé¡¹ç›®ç»“æ„åº”è¯¥å¦‚ä¸‹ï¼š

```
chatbi/
â”œâ”€â”€ src/chatbi/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py           # FastAPI ä¸»åº”ç”¨
â”‚   â”œâ”€â”€ config.py         # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ llm.py            # LLM å®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ cli/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ sql_explainer.py  # CLI å·¥å…·
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ sql.py        # SQL ç›¸å…³æ¨¡å‹
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ templates.py   # é€šç”¨æ¨¡æ¿
â”‚   â”‚   â””â”€â”€ sql_explainer.py  # SQL è§£é‡Š Prompt
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ sql_explainer.py  # SQL è§£é‡ŠæœåŠ¡
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ data.py       # æ•°æ®å¤„ç†å·¥å…·
â”‚       â”œâ”€â”€ async_utils.py
â”‚       â””â”€â”€ json_parser.py # JSON è§£æ
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_api.py
â”‚   â”œâ”€â”€ test_llm.py
â”‚   â””â”€â”€ test_sql_explainer.py
â”œâ”€â”€ docs/
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ Dockerfile
â””â”€â”€ docker-compose.yml
```

---

## éªŒæ”¶æ£€æŸ¥æ¸…å•

- [ ] Pandas åŸºç¡€æ“ä½œç†è§£ï¼ˆè¿‡æ»¤ã€åˆ†ç»„ã€æ’åºã€joinï¼‰
- [ ] å¼‚æ­¥æ–‡ä»¶è¯»å†™å¯ç”¨
- [ ] Prompt æ¨¡æ¿ç³»ç»Ÿå»ºç«‹
- [ ] Pydantic v2 æ¨¡å‹å®šä¹‰æ­£ç¡®
- [ ] JSON è§£æå’Œæ ¡éªŒé€»è¾‘å®Œå–„
- [ ] `POST /explain_sql` æ¥å£æ­£å¸¸å·¥ä½œ
- [ ] `sql-explainer` CLI å‘½ä»¤å¯ç”¨
- [ ] å•å…ƒæµ‹è¯•é€šè¿‡

---

## ä¸‹ä¸€æ­¥

å®Œæˆæœ¬é˜¶æ®µåï¼Œè¿›å…¥ [é˜¶æ®µ 2ï¼šRAG from scratch + LlamaIndex + å‘é‡æ•°æ®åº“](phase-2-rag-llamaindex-vectordb.md)
